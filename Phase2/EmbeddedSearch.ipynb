{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9609cfae",
   "metadata": {},
   "source": [
    "# <center> *Phase2(Part2):* **Embedded Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b73f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('D:\\AUT Courses\\Information Retrieval\\Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f730f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Phase1.PositionalBooleanSearch import read_documents, preprocess\n",
    "from Phase2.VectorizedSearch import load_dictionary, tfidf, retrieve_docs\n",
    "from Phase2.VectorizedSearch import Dictionary, Term\n",
    "from gensim.models import Word2Vec\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8ab833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data():\n",
    "    documents, titles = read_documents()\n",
    "    # print(len(documents))  # 7562\n",
    "    documents_tokens = preprocess(documents)\n",
    "    with open('..\\\\Phase2\\\\training_data.pkl', 'wb') as output:\n",
    "        pickle.dump(documents_tokens, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ae7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data():\n",
    "    with open('..\\\\Phase2\\\\training_data.pkl', 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd079d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    training_data = load_training_data()\n",
    "    cores = multiprocessing.cpu_count()\n",
    "\n",
    "    w2v_model = Word2Vec(min_count=1, window=5, vector_size=300, alpha=0.03, workers=cores - 1)\n",
    "    w2v_model.build_vocab(training_data)\n",
    "\n",
    "    w2v_model.train(training_data, total_examples=w2v_model.corpus_count, epochs=20)\n",
    "    w2v_model.save(\"w2v_model_300.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ab2593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_training_data()\n",
    "# build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894123f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model):\n",
    "    return Word2Vec.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d936e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_docs_tfidf_dict(dictionary):\n",
    "    documents_tokens = load_training_data()\n",
    "    docs_tfidf = []\n",
    "\n",
    "    for doc_id in range(len(documents_tokens)):\n",
    "        tokens = documents_tokens[doc_id]\n",
    "        doc_tfidf = {}\n",
    "        for token in tokens:\n",
    "            term = dictionary.get_term(token)\n",
    "            doc_tfidf[token] = term.tfidf_weight(doc_id, dictionary.N)\n",
    "        docs_tfidf.append(doc_tfidf)\n",
    "\n",
    "    return docs_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ba3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documents_embedding(model, dictionary):\n",
    "    docs_embedding = []\n",
    "    docs_tfidf = build_docs_tfidf_dict(dictionary)\n",
    "\n",
    "    for document in docs_tfidf:\n",
    "        doc_vector = np.zeros(300)\n",
    "        weights_sum = 0\n",
    "\n",
    "        for term, weight in document.items():\n",
    "            weights_sum += weight\n",
    "            try:\n",
    "                doc_vector += model.wv[term] * weight\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        if weights_sum == 0:\n",
    "            docs_embedding.append(doc_vector)\n",
    "            continue\n",
    "\n",
    "        docs_embedding.append(doc_vector / weights_sum)\n",
    "\n",
    "    return docs_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef664c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_documents_vectors(model, dictionary, file_name):\n",
    "    with open(\"..\\\\Phase2\\\\\" + file_name, 'wb') as output:\n",
    "        pickle.dump(documents_embedding(model, dictionary), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a73fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_vectors(file_name):\n",
    "    with open(\"..\\\\Phase2\\\\\" + file_name, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df7dc8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_embedding(query, model, dictionary):\n",
    "    query_terms = preprocess([query])[0]\n",
    "    query_vector = np.zeros(300)\n",
    "    weights_sum = 0\n",
    "\n",
    "    for qt in query_terms:\n",
    "        try:\n",
    "            qt_tf = query_terms.count(qt)\n",
    "            qt_df = dictionary.get_term(qt).df\n",
    "            weight = tfidf(qt_tf, qt_df, dictionary.N)\n",
    "            query_vector += model.wv[qt] * weight\n",
    "        except KeyError:\n",
    "            # print(qt)\n",
    "            continue\n",
    "        weights_sum += weight\n",
    "\n",
    "    if weights_sum == 0:\n",
    "        return query_vector\n",
    "\n",
    "    return query_vector / weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b865c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_search(query_vector, docs_vectors, dictionary, k):\n",
    "    similarity = {}\n",
    "    # print(norm(query_vector))\n",
    "    for doc_id in range(len(docs_vectors)):\n",
    "        doc_vector = docs_vectors[doc_id]\n",
    "        vectors_norm = norm(query_vector) * norm(doc_vector)\n",
    "        if vectors_norm == 0:\n",
    "            similarity[doc_id] = 0\n",
    "            continue\n",
    "        similarity_score = np.dot(query_vector, doc_vector) / vectors_norm\n",
    "        similarity[doc_id] = (similarity_score + 1) / 2\n",
    "\n",
    "    return retrieve_docs(similarity, dictionary, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9311353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"w2v_model_300.model\"\n",
    "d2v_file_name = \"d2v_model_300.pkl\"\n",
    "\n",
    "# model_name = \"w2v_150k_hazm_300_v2.model\"\n",
    "# d2v_file_name = \"d2v_150k_hazm_300_v2.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91ef99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_name)\n",
    "dictionary = load_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b361de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_documents_vectors(model, dictionary, d2v_file_name)\n",
    "docs_vectors = load_documents_vectors(d2v_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da9c5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Please Enter your Query: تفریغ بودجه\n",
      ">> Top 10 Results for «تفریغ بودجه» : \n",
      "====================\n",
      "آغاز جلسه غیرعلنی مجلس برای بررسی گزارش تفریغ بودجه ۹۹\n",
      "سی‌ودومین گزارش تفریغ بودجه ۲۰ مهر توسط بذرپاش در مجلس قرائت می‌شود\n",
      "بذرپاش اعلام کرد: رکوردشکنی در تفریغ بودجه 99/ نظارت دیوان محاسبات بر اجرای بودجه در مقاطع ۲ ماهه\n",
      "نظارت دیوان محاسبات بر اجرای بودجه سالانه در مقاطع ۲ ماهه را باید به فال نیک گرفت\n",
      "قالیباف: تا سه ماه آینده گزارش نهایی تفریغ بودجه 99 در صحن قرائت خواهد شد\n",
      "گام بلند دیوان محاسبات برای آنلاین شدن «تفریغ بودجه»/ پایانی بر گزارش‌های تاریخ گذشته از دخل و خرج‌ها\n",
      "دولت در شش ماهه نخست امسال 115 هزار میلیارد تومان برای هزینه‌های جاری اوراق فروخت\n",
      "دولت دوازدهم یارانه نقدی سه دهک بالای درآمدی را قطع نکرد\n",
      "تهیه دومین گزارش نظارت مستمر ۲ ماهه بر اجرای بودجه سال ۱۴۰۰\n",
      "گزارش تفریغ بودجه ۹۹ به تفکیک دستگاهی و استانی به زودی به مجلس می‌رسد\n",
      "===================================================\n",
      ">> Retrieval Time: --- 0.07848858833312988 seconds ---\n",
      "===================================================\n",
      ">> Please Enter your Query: وزارت نفت\n",
      ">> Top 10 Results for «وزارت نفت» : \n",
      "====================\n",
      "کاهش 30 درصدی سطح مخازن نیروگاه‌ها نسبت به سال گذشته/ تلاش وزارت نفت برای تأمین سوخت زمستانی\n",
      "تلاش وزارت نفت برای رفع نگرانی‌های تامین گاز زمستان\n",
      "وزیر نفت به رادیو اقتصاد می رود\n",
      "تشکیل کمیته مشترک کمیسیون انرژی و وزارت نفت برای لوایح بودجه سال 1401 و برنامه هفتم توسعه\n",
      "اختصاص ۲۰ میلیارد تومان به تیم نفت آبادان\n",
      "تشکیل کمیته مشترکی بین مجلس و وزارت نفت درباره لایحه بودجه سال ۱۴۰۱ و برنامه هفتم توسعه\n",
      "حضور وزیر نفت در کمیسیون برنامه و بودجه\n",
      "بررسی ذخیره سازی سوخت زمستانی در کمیسیون انرژی/ مذاکره با ترکمنستان برای واردات گاز\n",
      "نیروهای شرکتی در وزرات خانه‌ها تعیین تکلیف نشدند\n",
      "موانع واگذاری سهام دولت در شرکت پالایش نفت امام خمینی (ره) شازند بررسی و رفع شد\n",
      "===================================================\n",
      ">> Retrieval Time: --- 0.09413409233093262 seconds ---\n",
      "===================================================\n",
      ">> Please Enter your Query: \n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\">> Please Enter your Query: \", end='')\n",
    "    query = input()\n",
    "\n",
    "    if not query:\n",
    "        break\n",
    "\n",
    "    query_vector = query_embedding(query, model, dictionary)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\">> Top 10 Results for «%s» : \" % query)\n",
    "    print(\"====================\")\n",
    "    for result in embedded_search(query_vector, docs_vectors, dictionary, k=10):\n",
    "        print(result.strip())\n",
    "    print(\"===================================================\")\n",
    "    print(\">> Retrieval Time: --- %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"===================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
